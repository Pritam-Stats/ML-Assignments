{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c5281c40",
      "metadata": {
        "id": "c5281c40"
      },
      "source": [
        "### **1. What is Simple Linear Regression?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QzZHXtntoNEn",
      "metadata": {
        "id": "QzZHXtntoNEn"
      },
      "source": [
        "**Simple Linear Regression**\n",
        "\n",
        "- Definition:\n",
        "    > Simple Linear Regression (SLR) is a statistical method that models the relationship between two variables by fitting a straight line to the data. Simple linear regression is applied in case of one independent feature, otherwise in case of multiple features that becomes multiple linear regression. It helps us predict the dependent variable $Y$ based on the independent variable $X$.\n",
        "\n",
        "\n",
        "> The equation for Simple Linear Regression is:\n",
        "$Y = mX + c + \\epsilon $\n",
        "\n",
        "where:\n",
        "- $Y$ = dependent variable (response)\n",
        "- $X$= independent variable (predictor)\n",
        "- $ m$ = slope (rate of change of \\( Y \\) with respect to \\( X \\))\n",
        "- $ c$ = intercept (value of \\( Y \\) when \\( X = 0 \\))\n",
        "- $ \\epsilon $ = error term\n",
        "\n",
        "> Use Cases\n",
        "- Predicting house prices based on square footage.\n",
        "- Estimating salary based on years of experience.\n",
        "- Forecasting sales based on advertising spend.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b1fa024",
      "metadata": {
        "id": "4b1fa024"
      },
      "source": [
        "### **2. What are the key assumptions of Simple Linear Regression?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dGofI6TswYdw",
      "metadata": {
        "id": "dGofI6TswYdw"
      },
      "source": [
        "- For Simple Linear Regression (SLR) to be valid, the following assumptions must hold:\n",
        "\n",
        "    1. **Linearity**: The relationship between the independent variable \\(X\\) and the dependent variable \\(Y\\) is linear.\n",
        "    2. **Independence**: The residuals (errors) are independent of each other.\n",
        "    3. **Homoscedasticity**: The variance of residuals is constant across all levels of \\(X\\).\n",
        "    4. **Normality of Residuals**: The residuals should be normally distributed.\n",
        "    5. **No Perfect Multicollinearity**: This applies to Multiple Linear Regression, but in SLR, only one predictor exists.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f8cde1e",
      "metadata": {
        "id": "6f8cde1e"
      },
      "source": [
        "### **3. What does the coefficient m represent in the equation Y=mX+c?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZwHHEn_2xdhb",
      "metadata": {
        "id": "ZwHHEn_2xdhb"
      },
      "source": [
        "\n",
        "> The coefficient \\( m \\), known as the **slope** of the equation, represents the rate of change of \\( Y \\) with respect to \\( X \\).  \n",
        "\n",
        "- **Mathematical Interpretation:**  \n",
        "$m = \\frac{\\Delta Y}{\\Delta X}$\n",
        "  \n",
        "    - If \\( m \\) is **positive**, \\( Y \\) increases as \\( X \\) increases.\n",
        "    - If \\( m \\) is **negative**, \\( Y \\) decreases as \\( X \\) increases.\n",
        "    - If \\( m = 0 \\), \\( Y \\) does not change with \\( X \\).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "300fe52a",
      "metadata": {
        "id": "300fe52a"
      },
      "source": [
        "### **4. What does the intercept c represent in the equation Y=mX+c?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lkauc3JXzW4u",
      "metadata": {
        "id": "lkauc3JXzW4u"
      },
      "source": [
        "> The intercept \\( c \\) is the value of \\( Y \\) when \\( X = 0 \\). It represents the **baseline value** of the dependent variable. In other words c is the value where the line cuts the Y-axis when x = 0.\n",
        "\n",
        "\n",
        "- **interpretation:**  \n",
        "    - If \\( c \\) is **positive**, the regression line starts above zero.\n",
        "    - If \\( c \\) is **negative**, the regression line starts below zero.\n",
        "    - If \\( c = 0 \\), the line passes through the origin."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4190661c",
      "metadata": {
        "id": "4190661c"
      },
      "source": [
        "### **5. How do we calculate the slope m in Simple Linear Regression?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TTZjOGFG0p6i",
      "metadata": {
        "id": "TTZjOGFG0p6i"
      },
      "source": [
        "> The slope \\( m \\) is determined using the **least squares method**, which minimizes the sum of squared errors.\n",
        "\n",
        "- **Formula:**  \n",
        "$ \\min \\sum_{i=1}^{n} (Y_i - \\hat{Y_i})^2$\n",
        "\n",
        "where:\n",
        "- $Y_i$ is the actual value,\n",
        "- $ \\hat{Y_i} $ is the predicted value from the regression model,\n",
        "- The objective is to minimize the total squared difference between actual and predicted values.\n",
        "\n",
        "For **Simple Linear Regression**, let the equation for the best-fit line is:\n",
        "\n",
        "$Y = mX + c$\n",
        "\n",
        "and the **Least Squares Estimate** for the slope \\( m \\) comes out to be the following:\n",
        "\n",
        "$m = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum (X_i - \\bar{X})^2}$\n",
        "\n",
        "- $(X_i, Y_i)$ are individual data points.\n",
        "- $( \\bar{X}, \\bar{Y} )$ are the mean values of \\( X \\) and \\( Y \\).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f53729e",
      "metadata": {
        "id": "5f53729e"
      },
      "source": [
        "### **6. What is the purpose of the least squares method in Simple Linear Regression?**\n",
        "\n",
        "- **Definition:**  \n",
        "    > The **least squares method** is a mathematical optimization technique used in regression to find the best-fitting line by minimizing the sum of squared of errors (differences between actual and predicted values).\n",
        "\n",
        "- The goal is to minimize the sum of squared residuals:\n",
        "\n",
        "> $\\min \\sum_{i=1}^{n} (Y_i - \\hat{Y_i})^2$\n",
        "\n",
        "where:\n",
        "- $( Y_i)$ is the actual value.\n",
        "- $( \\hat{Y_i} = mX_i + c )$ is the predicted value from the regression line.\n",
        "\n",
        "- OLS method is mostly useful for small datasets\n",
        "> - **Purpose:**  \n",
        "    - Ensures that the regression line best represents the relationship between \\( X \\) and \\( Y \\).\n",
        "    - Reduces the impact of large errors by squaring residuals.\n",
        "    - Provides a standard method for estimating regression coefficients.\n",
        "    - Helps in making accurate predictions based on given data.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afeb41e5",
      "metadata": {
        "id": "afeb41e5"
      },
      "source": [
        "### **7. How is the coefficient of determination (RÂ²) interpreted in Simple Linear Regression?**\n",
        "\n",
        "- **Definition:**  \n",
        "    > The coefficient of determination $( R^2 )$ measures how well the independent variable $( X )$ explains the variability in the dependent variable $( Y )$. It indicates the goodness of fit of the regression model.\n",
        "\n",
        "- **Formula:**  \n",
        "    $R^2 = 1 - \\frac{\\text{Sum of Squared Errors (SSE)}}{\\text{Total Sum of Squares (SST)}}$\n",
        "    \n",
        "    $R^2 = 1 - \\frac{\\sum (Y_i - \\hat{Y_i})^2}{\\sum (Y_i - \\bar{Y})^2}$\n",
        "\n",
        "    where:\n",
        "    - **SSE (Sum of Squared Errors)**: How much our predictions **miss** the actual values.\n",
        "    - **SST (Total Sum of Squares)**: The **total variation** in $( Y )$, without considering $( X )$ means mathematically, it's $ \\sum (Y_i - \\bar{Y})^2$\n",
        "    \n",
        "    - **$( R^2 )$ is a ratio**: It compares the **error in our model** to the **total variation in data**.\n",
        "\n",
        "- **Interpretation and Properties:**  \n",
        "    - $( R^2 = 1 )$: The model perfectly explains the variance in $( Y )$ means perfect fit.\n",
        "    - $( R^2 = 0 )$: The model explains no variance in $( Y )$ (random prediction) NO fit.\n",
        "    - Higher $( R^2 )$ means a better fit, but it does not indicate causation.\n",
        "    - For example **$R^2 = 0.875$ means 87.5% of the variation in $Y$ can be explained by the dependent variable $X$** with that specific model.\n",
        "    - Higher $R^2$ **generally means better model fit** but not always. like adding more features which might not be helpful but that can increase the $R^2$ value artificially.\n",
        "    - Non-Linear relationships might have low $R^2$ even with a good model, and TO FIX THESE ISSUES, WE USE **Adjusted $R^2$**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89c257b1",
      "metadata": {
        "id": "89c257b1"
      },
      "source": [
        "### **8. What is Multiple Linear Regression?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfcbd460",
      "metadata": {},
      "source": [
        "\n",
        "- **Definition:**  \n",
        "    > Multiple Linear Regression (MLR) is an extension of Simple Linear Regression where *multiple independent variables* predict a single dependent variable.\n",
        "\n",
        "- **Equation:**  \n",
        "\n",
        "    $Y = b_0 + b_1X_1 + b_2X_2 + \\dots + b_nX_n + \\epsilon$\n",
        "\n",
        "    where:\n",
        "    - $Y$ = dependent variable.\n",
        "    - $(X_1, X_2, ..., X_n)$ = independent variables (predictors / features).\n",
        "    - $b_0$ = intercept.\n",
        "    - $(b_1, b_2, ..., b_n)$ = regression coefficients.\n",
        "    - $\\epsilon $ = error term.\n",
        "\n",
        "- **Use Cases:**\n",
        "    - Predicting house prices based on many other features like **size, location, and number of rooms**.\n",
        "    - Forecasting **sales** based on **advertising spend, season, and product type**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fecc939",
      "metadata": {
        "id": "4fecc939"
      },
      "source": [
        "### **9. What is the main difference between Simple and Multiple Linear Regression?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "155eee12",
      "metadata": {},
      "source": [
        "> **The key difference between SLR and MLR is the number of independent variable. Else,**\n",
        "\n",
        "| Feature               | Simple Linear Regression (SLR)  | Multiple Linear Regression (MLR) |\n",
        "|----------------------|----------------------------|----------------------------|\n",
        "| **Number of Predictors** | 1 independent variable $(X)$ | Multiple independent variables $(X_1, X_2, ..., X_n)$ |\n",
        "| **Equation** | $( Y = mX + c )$ | $( Y = b_0 + b_1X_1 + b_2X_2 + ... + b_nX_n)$ |\n",
        "| **Complexity** | Simple | More complex due to multiple predictors |\n",
        "| **Interpretation** | Easy to understand | Requires handling of multi-collinearity |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6286ae4f",
      "metadata": {
        "id": "6286ae4f"
      },
      "source": [
        "### **10. What are the key assumptions of Multiple Linear Regression?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e387f7a4",
      "metadata": {},
      "source": [
        "    > Multiple Linear Regression relies on specific assumptions to provide valid and interpretable results.\n",
        "\n",
        "- **Key Assumptions:**\n",
        "    1. **Linearity**: The relationship between  $X$ and $Y$ must be linear.\n",
        "    2. **Independence**: Observations must be independent.\n",
        "    3. **Homoscedasticity**: Residual variance must be constant.\n",
        "    4. **Normality of Residuals**: Residuals should be normally distributed.\n",
        "    5. **No Multicollinearity**: Independent variables should not be highly correlated.\n",
        "    6. **No Autocorrelation**: Residuals should not be correlated (important for time series data).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "895f8bbe",
      "metadata": {
        "id": "895f8bbe"
      },
      "source": [
        "### **11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a568620c",
      "metadata": {},
      "source": [
        "- **Definition:**  \n",
        "    > Heteroskedasticity occurs when the variance of residuals is **not constant** across all levels of $X$.\n",
        "\n",
        "- **Effect on Model:**\n",
        "    - Violates the assumption of constant variance.\n",
        "    - Makes predictions less reliable.\n",
        "    - Leads to biased standard errors, affecting hypothesis testing.\n",
        "\n",
        "- **Detection Methods:**\n",
        "    - **Residual Plots**: A non-random pattern in residuals indicates heteroscedasticity.\n",
        "    - **Breusch-Pagan Test**: A statistical test for heteroscedasticity.\n",
        "\n",
        "- **Fixing Methods:**\n",
        "    - **Log Transformation** of the dependent variable.\n",
        "    - **Weighted Least Squares (WLS)** regression.\n",
        "    - **Using robust standard errors**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "731922db",
      "metadata": {
        "id": "731922db"
      },
      "source": [
        "### **12. How can you improve a Multiple Linear Regression model with high multicollinearity?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "291efd5e",
      "metadata": {},
      "source": [
        "\n",
        "> Multicollinearity occurs when two or more independent variables are highly correlated, makes it difficult to determine their individual effects on $Y$.\n",
        "- **Detection Methods:**\n",
        "    - **Variance Inflation Factor (VIF)**: If $VIF > 5$, multicollinearity is a concern.\n",
        "    - **Correlation Matrix**: High correlations $( > 0.8 )$ between predictors suggest multicollinearity.\n",
        "\n",
        "- **Solutions:**\n",
        "    - Remove highly correlated variables.\n",
        "    - Use **Principal Component Analysis (PCA)** to reduce dimensionality.\n",
        "    - Use **Ridge Regression or Lasso Regression** for better coefficient estimation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f66ed8f",
      "metadata": {
        "id": "2f66ed8f"
      },
      "source": [
        "### **13. What are some common techniques for transforming categorical variables for use in regression models?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec39e058",
      "metadata": {},
      "source": [
        " \n",
        "> Categorical variables must be converted into numerical form using various encoding technique before being used in regression models.\n",
        "\n",
        "- **Common Techniques:**\n",
        "    - **One-Hot Encoding (OHE)**: Creates binary variables for each category.\n",
        "    - **Label Encoding**: Assigns numerical values to categories (e.g., Male = 0, Female = 1).\n",
        "    - **Ordinal Encoding**: Used when categories have a meaningful order (e.g., Low < Medium < High).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7be95bfc",
      "metadata": {
        "id": "7be95bfc"
      },
      "source": [
        "### **14. What is the role of interaction terms in Multiple Linear Regression?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe58eb89",
      "metadata": {},
      "source": [
        "> Interaction terms capture the combined effect of two independent variables on $Y$.\n",
        "\n",
        "- **Equation with Interaction Term:**\n",
        "    $Y = b_0 + b_1X_1 + b_2X_2 + b_3(X_1 \\times X_2) + \\epsilon$\n",
        "    \n",
        "- **Use Cases:**\n",
        "    - In **marketing**, an increase in **ad spend** and a **holiday season** together may impact sales more than individually.\n",
        "    - In **health studies**, the combined effect of **exercise** and **diet** may influence weight loss more than either alone.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fef7356e",
      "metadata": {
        "id": "fef7356e"
      },
      "source": [
        "### **15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f393f8f",
      "metadata": {},
      "source": [
        "- **In Simple Linear Regression **$Y = mX + c$**:\n",
        "    - The **intercept $( c )$** represents the predicted value of $( Y )$ when $ X = 0 $.\n",
        "\n",
        "- **In Multiple Linear Regression $( Y = b_0 + b_1X_1 + b_2X_2 + ... )$**:\n",
        "    - The **intercept $( b_0 )$** represents the predicted $( Y )$ when **all** independent variables are zero.\n",
        "\n",
        "- **Important Consideration:**\n",
        "    - If $X$ values never approach zero, the intercept may have no meaningful interpretation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "863fb55b",
      "metadata": {
        "id": "863fb55b"
      },
      "source": [
        "### **16. What is the significance of the slope in regression analysis, and how does it affect predictions?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74a1a9c0",
      "metadata": {},
      "source": [
        "\n",
        "- The **slope** in regression represents the **rate of change** of the dependent variable (\\( Y \\)) with respect to the independent variable (\\( X \\)).\n",
        "- It tells us **how much \\( Y \\) changes for a one-unit increase in \\( X \\)**.\n",
        "\n",
        "- For **Simple Linear Regression**, the equation is:\n",
        "\n",
        "    $Y = mX + c$\n",
        "\n",
        "where:\n",
        "- $( c )$ = intercept\n",
        "- $( Y )$ = predicted value\n",
        "- $( m )$ = **slope** (coefficient of \\( X \\))\n",
        "- $( X )$ = independent variable\n",
        "\n",
        "The slope is calculated as:\n",
        "\n",
        "$m = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum (X_i - \\bar{X})^2}$\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "- **Significance of the Slope**\n",
        "    1. **Direction of Relationship**\n",
        "        - If  $m > 0$, **positive correlation**: As $X$ increases, $Y$ also increases.\n",
        "        - If  $m < 0$, **negative correlation**: As $X$ increases, $Y$ decreases.\n",
        "        - If  $m = 0$, **no correlation**: Changes in  $X$ have no effect on $Y$.\n",
        "\n",
        "2. **Magnitude of Change**\n",
        "   - The **larger** the absolute value of \\( m \\), the **steeper** the slope, meaning \\( Y \\) changes **more rapidly** with \\( X \\).\n",
        "   - A **small slope** means \\( Y \\) changes **slowly** with \\( X \\).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06833675",
      "metadata": {
        "id": "06833675"
      },
      "source": [
        "### **17. How does the intercept in a regression model provide context for the relationship between variables?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b2897a9",
      "metadata": {},
      "source": [
        "\n",
        "- The **intercept** (\\( c \\)) represents the predicted value of \\( Y \\) when \\( X = 0 \\).\n",
        "- It is the **baseline value** of the dependent variable before considering the effect of \\( X \\).\n",
        "\n",
        "- For Simple Linear Regression:\n",
        "\n",
        "$Y = mX + c$\n",
        "\n",
        "where \\( c \\) is the intercept.\n",
        "\n",
        "---\n",
        "\n",
        "- **Significance of the Intercept**\n",
        "    1. **Starting Value of \\( Y \\)**\n",
        "        - If \\( X = 0 \\), the predicted \\( Y \\) is simply \\( c \\).\n",
        "        - This gives a reference starting point for the model.\n",
        "\n",
        "2. **Real-World Meaning**\n",
        "   - In **some cases**, the intercept makes sense (e.g., predicting height from age).\n",
        "   - In **other cases**, it may be **meaningless** (e.g., predicting salary from years of experience when \\( X = 0 \\) is not realistic).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37904903",
      "metadata": {
        "id": "37904903"
      },
      "source": [
        "### **18. What are the limitations of using RÂ² as a sole measure of model performance?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a0a5b20",
      "metadata": {},
      "source": [
        "\n",
        "$R^2$ tells us **how much variation in \\( Y \\) is explained by \\( X \\) for using the model**, but it has some **limitations**:\n",
        "\n",
        "\n",
        "1. **Adding More Features Increases \\( R^2 \\) Artificially**\n",
        "   - Even more **random variables** can increase \\( R^2 \\).\n",
        "   - A high \\( R^2 \\) doesnât always mean the model is **good**.\n",
        "\n",
        "3. **It Ignores Model Complexity**\n",
        "   - A **simple** model with an \\( R^2 \\) of 0.75 might be **better** than a complex one with \\( R^2 = 0.80 \\).\n",
        "\n",
        "---\n",
        "\n",
        "- **Example: Predicting House Prices**\n",
        "\n",
        "| Model | Features Used | \\( R^2 \\) |\n",
        "|-------|--------------|-----------|\n",
        "| Model 1 | Square footage | 0.75 |\n",
        "| Model 2 | Square footage + Zip Code | 0.80 |\n",
        "| Model 3 | Square footage + Zip Code + Number of Pets | 0.85 |\n",
        "\n",
        "- **Model 3 has the highest \\( R^2 \\)**, but **\"Number of Pets\"** has no real impact on house prices.\n",
        "- This leads to **overfitting**, where the model fits **noise instead of patterns**.\n",
        "\n",
        "---\n",
        "\n",
        "- **Better Alternatives to \\( R^2 \\)**\n",
        "   1. **Adjusted \\( R^2 \\)**: Penalizes adding useless features.\n",
        "   2. **Mean Squared Error (MSE)**: Measures actual prediction error.\n",
        "   3. **Cross-validation**: Checks how well the model generalizes.\n",
        "\n",
        "As a conclusion we can note that \\( $R^2$ \\) **alone** is not enough; always check for **overfitting, causation, and real-world relevance**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eabc5125",
      "metadata": {
        "id": "eabc5125"
      },
      "source": [
        "### **19. How would you interpret a large standard error for a regression coefficient?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "542daa80",
      "metadata": {},
      "source": [
        "\n",
        "**Standard Error of a Coefficient**\n",
        "    - The **standard error (SE)** measures **the uncertainty in the estimate** of a regression coefficient.\n",
        "    - A **large SE** means the coefficient **is not estimated precisely**.\n",
        "\n",
        "**Interpretation of a Large Standard Error**\n",
        "    - A **large SE** means:\n",
        "      - The estimated coefficient is **unstable**.\n",
        "      - There is **high variability** in the relationship between \\( X \\) and \\( Y \\).\n",
        "      - The predictor **may not be important**.\n",
        "\n",
        "- **If SE is large relative to the coefficient**, the confidence interval is wide, meaning predictions are **less reliable**.\n",
        "\n",
        " **Example: Predicting House Prices**\n",
        "\n",
        "| Variable | Coefficient (\\( b \\)) | Standard Error (\\( SE \\)) |\n",
        "|----------|----------------|----------------|\n",
        "| Square Footage | 200 | 15 |\n",
        "| Number of Pets | 5 | 50 |\n",
        "\n",
        "- **Square footage has a small SE**, meaning it is a **strong predictor**.\n",
        "- **Number of Pets has a large SE**, meaning it **adds noise** and is **not reliable**.\n",
        "\n",
        "\n",
        "- A **large SE** suggests a **weak predictor or insufficient data**.\n",
        "- **Reduce SE** by **adding more data** or **removing irrelevant variables**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f89aeb57",
      "metadata": {
        "id": "f89aeb57"
      },
      "source": [
        "### **20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd3902e9",
      "metadata": {},
      "source": [
        "**Heteroscedasticity-**\n",
        "    - **Heteroscedasticity** means that the **variance of residuals** is **not constant**.\n",
        "    - In a good regression model, residuals should have **constant variance**.\n",
        "\n",
        "**Identifying Heteroscedasticity**\n",
        "\n",
        "1. **Residual Plot Analysis**\n",
        "    - Plot **Residuals vs. Predicted Values**.\n",
        "    - If residuals form a **funnel shape (increasing spread)**, heteroscedasticity is present.\n",
        "       \n",
        "2. **Statistical Tests**\n",
        "    - **Breusch-Pagan Test**: Detects heteroscedasticity.\n",
        "    - **Whiteâs Test**: Another method for checking variance inconsistency.\n",
        "\n",
        "- **Why is it Important?**\n",
        "    - **Biases standard errors**, leading to **incorrect hypothesis tests**.\n",
        "    - Makes predictions **less reliable**.\n",
        "\n",
        "**Fixing Heteroscedasticity**\n",
        "    - **Log Transform** dependent variable (\\( Y \\)).\n",
        "    - Use **Weighted Least Squares (WLS)**.\n",
        "    - Apply **Heteroscedasticity-Robust Standard Errors**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3414570",
      "metadata": {
        "id": "f3414570"
      },
      "source": [
        "### **21. What does it mean if a Multiple Linear Regression model has a high RÂ² but low adjusted RÂ²?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ccd2d1e",
      "metadata": {},
      "source": [
        "\n",
        "- **$R^2$** increases when we add more predictors/features, even if they are **useless**.\n",
        "- **Adjusted $R^2$** penalizes unnecessary predictors, adjusting for model complexity.\n",
        "\n",
        "**Interpretation of High $R^2$ and Low Adjusted $R^2$**:\n",
        "\n",
        "  - The model **have irrelevant features**.\n",
        "  - Extra variables **do not improve the model** but **inflate $R^2$ artificially**.\n",
        "\n",
        "- **Example**\n",
        "\n",
        "| Model | Features | $R^2$ | Adjusted $R^2$ |\n",
        "|-------|---------|------|--------------|\n",
        "| Model 1 | Square Footage | 0.80 | 0.78 |\n",
        "| Model 2 | Square Footage + Number of Pets | 0.85 | 0.70 |\n",
        "\n",
        "- Model 2 has **higher \\( R^2 \\)** but **lower Adjusted \\( R^2 \\)**, meaning **\"Number of Pets\" adds no real value**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71c63a4f",
      "metadata": {
        "id": "71c63a4f"
      },
      "source": [
        "### **22. Why is it important to scale variables in Multiple Linear Regression?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d04c6de",
      "metadata": {},
      "source": [
        "- **Why Scale Variables?**\n",
        "\n",
        "  - In Multiple Linear Regression, predictors can have **different ranges**.\n",
        "  - **Scaling ensures fair comparison** by bringing all variables to a similar scale.\n",
        "\n",
        "**Effects of Not Scaling**\n",
        "  1. **Incorrect Coefficient Interpretation** - Large-scale variables dominate smaller ones.\n",
        "  2. **Slow Gradient Descent Convergence** - In machine learning models like linear regression with *gradient-based optimization*, unscaled variables slow learning.\n",
        "\n",
        "**Methods to Scale Variables**\n",
        "  - **Standardization** (Z-score scaling):\n",
        "  \n",
        "  $X' = \\frac{X - \\bar{X}}{\\sigma}$\n",
        "\n",
        "  - **Min-Max Scaling** (0-1 scaling):\n",
        "    \n",
        "  $X' = \\frac{X - X_{\\min}}{X_{\\max} - X_{\\min}}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39b8ff5c",
      "metadata": {
        "id": "39b8ff5c"
      },
      "source": [
        "### **23. What is polynomial regression?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c7d744d",
      "metadata": {},
      "source": [
        "**Definition**\n",
        "    - Polynomial Regression is an **extension of Linear Regression** that models **non-linear relationships**.\n",
        "\n",
        "**n-th degree polynomial Equation -**\n",
        "\n",
        "$Y = b_0 + b_1X + b_2X^2 + b_3X^3 + ... + b_nX^n + \\epsilon$\n",
        "\n",
        "\n",
        "- Higher degree adds more curvatures in the model.\n",
        "\n",
        "**Example: Predicting House Prices**\n",
        "- Linear Model: **\\( Y = 200X + 50,000 \\)**\n",
        "- Polynomial Model: **\\( Y = 5X^2 + 200X + 50,000 \\)** (captures non-linearity/curves)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0254d938",
      "metadata": {
        "id": "0254d938"
      },
      "source": [
        "### **24. How does polynomial regression differ from linear regression?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86f277e3",
      "metadata": {},
      "source": [
        "**Key Difference is that Polynomial regression captures the curvature the data if any**\n",
        "\n",
        "| Feature | Linear Regression | Polynomial Regression |\n",
        "|---------|----------------|----------------|\n",
        "| **Equation** | Y = mX + c  | $Y = b_0 + b_1X + b_2X^2 + ...$ |\n",
        "| **Fit Model Shape** | Straight line | Curved line |\n",
        "| **Use Case** | Linear relationships | Non-linear relationships |\n",
        "| **Overfitting Risk** | Low | Higher for high-degree polynomials |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7364fc8",
      "metadata": {
        "id": "f7364fc8"
      },
      "source": [
        "### **25. When is polynomial regression used?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64833ab2",
      "metadata": {},
      "source": [
        "\n",
        "- When data shows a **curved pattern** that linear regression may not capture well enough.\n",
        "\n",
        "**Example: Growth of a Business**\n",
        "\n",
        "- A startup's revenue may **grow exponentially** rather than linearly.\n",
        "- Polynomial Regression captures **non-linear growth trends**.\n",
        "\n",
        "In conclusion, we use polynomial regression when the data points indicates non-linear relations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc9eeef7",
      "metadata": {
        "id": "cc9eeef7"
      },
      "source": [
        "### **26. What is the general equation for polynomial regression?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19453fe2",
      "metadata": {},
      "source": [
        "\n",
        "A **Polynomial Regression model** extends Linear Regression by including **higher-degree terms** which adds the curves:\n",
        "\n",
        "In general a *n-th degree* polynomial regression equation is-\n",
        "\n",
        "$Y = b_0 + b_1X + b_2X^2 + b_3X^3 + \\dots + b_nX^n + \\epsilon$\n",
        "\n",
        "where:\n",
        "- $b_0$ = **Intercept**\n",
        "- $b_1, \\dots, b_n$ = **coefficients**.\n",
        "- $X^n$ = **n-th-degree term** to capture non-linearity.\n",
        "- $\\epsilon$ = **error term**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5baf984a",
      "metadata": {
        "id": "5baf984a"
      },
      "source": [
        "### **27. Can polynomial regression be applied to multiple variables?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55bf9557",
      "metadata": {},
      "source": [
        "\n",
        "For **two variables $(X_1, X_2)$**, our polynomial equation becomes:\n",
        "\n",
        "$Y = b_0 + b_1X_1 + b_2X_2 + b_3X_1^2 + b_4X_2^2 + b_5X_1X_2 + \\dots + \\epsilon$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f35d26f",
      "metadata": {
        "id": "3f35d26f"
      },
      "source": [
        "### **28. What are the limitations of polynomial regression?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed1ee7e7",
      "metadata": {},
      "source": [
        "**Key Limitations**\n",
        "\n",
        "1. **Overfitting**\n",
        "   - High-degree polynomials fit training data well but fail on new data.\n",
        "\n",
        "2. **Computational Complexity**\n",
        "   - Large-degree polynomials increase computation time.\n",
        "\n",
        "3. **Extrapolation Issues**\n",
        "   - Predictions outside training data range become highly unreliable.\n",
        "\n",
        "4. **Collinearity**\n",
        "   - Higher-degree terms **correlate strongly**, causing **unstable coefficients**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c8cd04f",
      "metadata": {
        "id": "0c8cd04f"
      },
      "source": [
        "### **29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a238774b",
      "metadata": {},
      "source": [
        "**Evaluation Methods**\n",
        "\n",
        "1. **Adjusted \\( R^2 \\)**\n",
        "   - Penalizes **useless features addition**, preventing **overfitting**.\n",
        "\n",
        "2. **Cross-Validation**\n",
        "   - Splits data into **training and testing sets** to evaluate **real performance**.\n",
        "\n",
        "3. **Mean Squared Error (MSE)**\n",
        "\n",
        "   $MSE = \\frac{1}{n} \\sum (Y_i - \\hat{Y_i})^2$\n",
        "\n",
        "4. **Visualization**\n",
        "   - Plot **predictions vs. actual data** to check for **overfitting or underfitting**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37b3f523",
      "metadata": {
        "id": "37b3f523"
      },
      "source": [
        "### **31. Why is visualization important in polynomial regression?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce92bad0",
      "metadata": {},
      "source": [
        "**Importance of Visualization**\n",
        "\n",
        "1. **To Detect Overfitting or Underfitting**\n",
        "   - Helps to see how well the curve fits the data.\n",
        "\n",
        "2. **Validates Model Choice**\n",
        "   - Ensures the selected **polynomial degree** is appropriate.\n",
        "\n",
        "3. **Interprets Model Behavior**\n",
        "   - Shows where the model makes **unrealistic predictions**.\n",
        "\n",
        "**Example**\n",
        "- Scatter plot + Regression curve:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a035d2a4",
      "metadata": {
        "id": "a035d2a4"
      },
      "source": [
        "### **32. How is polynomial regression implemented in Python?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dc4b3ec",
      "metadata": {},
      "source": [
        "using `PolynomialFeatures` from the scikit-learn library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "41872357",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "18582157",
      "metadata": {},
      "outputs": [],
      "source": [
        "X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9]).reshape(-1,1)\n",
        "Y = np.array([3, 7, 9, 12, 30, 39, 41, 59, 75])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "05362aef",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.,  1.,  1.],\n",
              "       [ 1.,  2.,  4.],\n",
              "       [ 1.,  3.,  9.],\n",
              "       [ 1.,  4., 16.],\n",
              "       [ 1.,  5., 25.],\n",
              "       [ 1.,  6., 36.],\n",
              "       [ 1.,  7., 49.],\n",
              "       [ 1.,  8., 64.],\n",
              "       [ 1.,  9., 81.]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transforming X to polynomial\n",
        "\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "x_poly = poly.fit_transform(X)\n",
        "\n",
        "x_poly  # gives $X^0 , X**1, X^2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "0e19ee1f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9, 3)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_poly.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "53186aae",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"â¸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"â¾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = LinearRegression()  #creating an LR object\n",
        "model.fit(x_poly, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "91c88228",
      "metadata": {},
      "outputs": [],
      "source": [
        "Y_predicted = model.predict(x_poly)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "04f4ecef",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.scatter(X, Y, color='red', label='Actual Data')\n",
        "plt.plot(X, Y_predicted, color='blue', label='Polynomial Fit (deg = 2)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "f1de3101",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "70c3013b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9805654231343186"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "R2 = r2_score(Y, Y_predicted)\n",
        "R2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2765041c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9740872308457581"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Adjusted R2\n",
        "n = len(Y)\n",
        "p = x_poly.shape[1] - 1 #No of linearly independent Features (-1 is to exclude the intercept)\n",
        "\n",
        "adjusted_R2 = 1 - (((1 - R2) * (n - 1)) / (n - p - 1) )\n",
        "adjusted_R2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "5c8760c1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R^2 = 0.981\n",
            "Adjusted R^2 = 0.974\n"
          ]
        }
      ],
      "source": [
        "print(f\"R^2 = {R2:.3f}\")\n",
        "print(f\"Adjusted R^2 = {adjusted_R2:.3f}\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "883ec1f5",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
